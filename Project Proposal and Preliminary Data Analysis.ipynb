{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3804ICT Fandoms Connect\n",
    "\n",
    "This document contains the project proposal and preliminary data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preface\n",
    "\n",
    "Thanks to the internet and the rise of internet message boards to the wider public such as Reddit, 4chan and not Newsgroups, the past 5 years have never been a better time for fans of pop-culture and interest groups to connect with one another. However, despite the internet being interconnected and everything out in the open, there is still the tendency for groups of people to clump up or join the same set of groups (which is still clumping up).\n",
    "\n",
    "The aim of the investigation is to see what percentage of users belong to which fandoms, and how different fandoms overlap or avoid each other. For example: Do Digimon fans also interact with those who also like Pokémon, and vice versa<sup>[1]</sup>?\n",
    "\n",
    "In order to gather the data, first, uses are aggregated and posts are scraped of Reddit using the Reddit API<sup>[2]</sup>. This is a real-world dataset using live data straight from a live social media website as source. Users, posts and comments are scraped from my profile ([/u/aytimothy](https://reddit.com/u/aytimothy)) through any interactions made to me, or by me. These scraped users are then added into a queue, where the same is repeated on them. Using the raw post data of \\[parent, user, score, subreddit, content\\], we can then clean it into a machine-usable state by using text analysis to build our database of data points. Before processing, we can already see content by their authors, communities posted to and upvotes. From there, we can look at the comments to see what is being mentioned where. Keywords, for example such as Pokémon names can be used to signify that a person knows about, well, Pokémon.\n",
    "\n",
    "In order to work out how likely a person from a fandom is part or knows about another, we can emply methods such as Apriori or FP-Trees to class users into their fandoms, and, to work out (theatrically) where new users may sit within the multi-dimensions of different fandoms and how likely is one to interact/be part of in another. As for how ‘correct’ or ‘wrong’ we are, we can simply scrape the user’s profile to see if they have actually interacted in a community or not. Repeat for many users, and this is our measurement of accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Data Analysis\n",
    "\n",
    "> Note: The data is currently being scraped, and this information does not reflect the whole dataset.\n",
    "\n",
    "**This information is correct as of the 6th of August, 9:01 PM. Since this is a continious mining operation, some numbers may change while I'm working out the answers.**\n",
    "\n",
    "* 635,332 comments and 6,989 submissions have been processed from Reddit, after approximately 60 hours of runtime.\n",
    "* We have processed the entire post/comment history of 82 users.\n",
    "* There are 340,817 unique users for comments and 3,312 for submissions in the database.\n",
    "* There are 1,325 unique communities between all comments, and 1,473 between all submissions.\n",
    "* There are 394 submissions and 31,985 comments created by deleted users. \n",
    "* There were 3,397 comments and 311 submissions removed by moderators. \n",
    "* There were 9,826 comments and 302 submissions deleted by their authors.\n",
    "* The collection crashed again at 9:11 PM because of unhandled Error 404s.\n",
    "\n",
    "Submissions and comments are distributed as follows:\n",
    "\n",
    "|Property|Min|Q1|Median|Q3|Max|Mean|\n",
    "|--------|---|--|------|--|---|----|\n",
    "|Submission Score|0|3|35|466 - 467|153,793|3139.2162|\n",
    "|Comment Score|-532|1|4|17|58,234|116.9329|\n",
    "\n",
    "<p><div style=\"text-align: center\">[INSERT BOX PLOT AND HISTOGRAM HERE]</div></p>\n",
    "\n",
    "Minimums are maximums are skewed while the medians still trend in positive numbers as only the outliers generate high/low scores. Most comments/submissions get few or little upvotes. \n",
    "\n",
    "Finally, a few more interesting information about the content that was scraped:\n",
    "\n",
    "\n",
    "* The most up-voted submission is a [picture of a cat](https://www.reddit.com/r/aww/comments/ckbolc/this_is_tiger_he_just_turned_31_we_are_told_he_is/) from [/r/aww](https://reddit.com/r/aww) with a score of 153,793.\n",
    "* A [Rick Roll](https://youtu.be/dQw4w9WgXcQ); Rick Astley - Never Gonna Give You Up was the fifth [highest scoring post](https://www.reddit.com/r/videos/comments/5gafop/rick_astley_never_gonna_give_you_up_sped_up_every/) collected.\n",
    "* [/u/SovietRussiaBot](https://reddit.com/u/SovietRussiaBot) holds the 1st, 3rd and 5th most downvoted comment. It's a [bot](https://github.com/dneu/SovietRussiaBot) that replies to anything it considers a [Russian Reversal](https://en.wikipedia.org/wiki/Russian_reversal) joke, and also uses `praw`.\n",
    "* The [top comment](https://www.reddit.com/r/AskReddit/comments/bu1s5i/what_fact_is_common_knowledge_to_people_who_work/ep6aqhz/) is about elevators when they have a catastrophic failure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality, Completeness and Noise \n",
    "\n",
    "Because the data collected is everything and anything, there are bound to be useless or irrelevant, such as my post to [sell a Westfield Giftcard](https://www.reddit.com/r/giftcardexchange/comments/cep1a8/h_westfield_gift_card_470_aud_w_offer_paypal_cash/). Meta subreddits (such as [/r/gaming](https://reddit.com/r/gaming)) are good for diversifying your data and finding starting points, but also comes with a lot of fluff. Furthermore, as stated above, there are also posts by deleted users or were removed due to moderation reasons.\n",
    "\n",
    "Next, it does not meet the minimum of 10 dimensions, which is possible to expand on by checking the text. References to other fandoms don’t own occur in a user submitting a post or commenting in one, but also by reference. For example, for pet monster franchises (ie. Pokémon, Tamagotchi or Digimon), we can search the bodies of text for references to their subreddit (anything beginning in an “/r/” and applies universally) or actual monster names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Original Research: Older audiences of both franchises (the 1999 to 2003 demographic who were ages 6 to 18 at the time, or parents) are aware of each other due to the virtual pet and early toy gatcha market. This later spread down the line towards the current younger generation (these people are now in their late teens to adulthood as of 2019).  \n",
    "[2] [https://www.reddit.com/wiki/api](https://www.reddit.com/wiki/api)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
